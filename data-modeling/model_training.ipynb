{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIT License\n",
    "\n",
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "This notebook is adapted from Francesca Lazzeri Energy Demand Forecast Workbench workshop.\n",
    "\n",
    "Copyright (c) 2021 PyLadies Amsterdam, Alyona Galyeva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression with recursive feature elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Callable\n",
    "# from azureml.core import Workspace, Dataset\n",
    "# from azureml.core.experiment import Experiment\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to train a linear regression model to create a forecast of future energy demand. In particular, the model will be trained to predict energy demand in period $t_{+1}$, one hour ahead of the current time period $t$. This is known as 'one-step' time series forecasting because we are predicting one period into the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/brandon/Desktop/ccClub/ccClub 2021 Fall/Final_Project/ccclub-advanced-final/data-modeling'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKDIR = os.getcwd()\n",
    "TRAIN_DIR = os.path.join(WORKDIR, '../data-processing/data/train')\n",
    "TEST_DIR = os.path.join(WORKDIR, '../data-processing/data/test')\n",
    "MODEL_NAME = \"linear_regression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The local variable of type DataFrame, df_train_4 is created\n",
      "The local variable of type DataFrame, df_train_3 is created\n",
      "The local variable of type DataFrame, df_train_2 is created\n",
      "The local variable of type DataFrame, df_train_1 is created\n",
      "The local variable of type DataFrame, df_outlier_train_4 is created\n",
      "The local variable of type DataFrame, df_outlier_train_3 is created\n",
      "The local variable of type DataFrame, df_outlier_train_2 is created\n",
      "The local variable of type DataFrame, df_outlier_train_1 is created\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>solar_ghi</th>\n",
       "      <th>solar_prediction_mw</th>\n",
       "      <th>wind_prediction_mw</th>\n",
       "      <th>load_actuals_mw</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>month</th>\n",
       "      <th>season</th>\n",
       "      <th>workdayornot</th>\n",
       "      <th>temperature_lag1</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_prediction_mw_lag3</th>\n",
       "      <th>wind_prediction_mw_lag4</th>\n",
       "      <th>wind_prediction_mw_lag5</th>\n",
       "      <th>wind_prediction_mw_lag6</th>\n",
       "      <th>solar_prediction_mw_lag1</th>\n",
       "      <th>solar_prediction_mw_lag2</th>\n",
       "      <th>solar_prediction_mw_lag3</th>\n",
       "      <th>solar_prediction_mw_lag4</th>\n",
       "      <th>solar_prediction_mw_lag5</th>\n",
       "      <th>solar_prediction_mw_lag6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>134.6351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.9495</td>\n",
       "      <td>89.6098</td>\n",
       "      <td>2020-01-01 02:30:00+01:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>134.6573</td>\n",
       "      <td>...</td>\n",
       "      <td>64.3057</td>\n",
       "      <td>66.9774</td>\n",
       "      <td>69.2968</td>\n",
       "      <td>70.8654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>134.6129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.5166</td>\n",
       "      <td>88.3333</td>\n",
       "      <td>2020-01-01 02:45:00+01:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>134.6351</td>\n",
       "      <td>...</td>\n",
       "      <td>61.1283</td>\n",
       "      <td>64.3057</td>\n",
       "      <td>66.9774</td>\n",
       "      <td>69.2968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134.5925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.2634</td>\n",
       "      <td>87.3941</td>\n",
       "      <td>2020-01-01 03:00:00+01:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>134.6129</td>\n",
       "      <td>...</td>\n",
       "      <td>57.2304</td>\n",
       "      <td>61.1283</td>\n",
       "      <td>64.3057</td>\n",
       "      <td>66.9774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134.5740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.7925</td>\n",
       "      <td>86.6259</td>\n",
       "      <td>2020-01-01 03:15:00+01:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>134.5925</td>\n",
       "      <td>...</td>\n",
       "      <td>53.9495</td>\n",
       "      <td>57.2304</td>\n",
       "      <td>61.1283</td>\n",
       "      <td>64.3057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134.5555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.2637</td>\n",
       "      <td>86.3420</td>\n",
       "      <td>2020-01-01 03:30:00+01:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>134.5740</td>\n",
       "      <td>...</td>\n",
       "      <td>50.5166</td>\n",
       "      <td>53.9495</td>\n",
       "      <td>57.2304</td>\n",
       "      <td>61.1283</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   temperature  solar_ghi  solar_prediction_mw  wind_prediction_mw  \\\n",
       "0     134.6351        0.0                  0.0             53.9495   \n",
       "1     134.6129        0.0                  0.0             50.5166   \n",
       "2     134.5925        0.0                  0.0             47.2634   \n",
       "3     134.5740        0.0                  0.0             44.7925   \n",
       "4     134.5555        0.0                  0.0             42.2637   \n",
       "\n",
       "   load_actuals_mw                  timestamp  month  season  workdayornot  \\\n",
       "0          89.6098  2020-01-01 02:30:00+01:00      1       1             0   \n",
       "1          88.3333  2020-01-01 02:45:00+01:00      1       1             0   \n",
       "2          87.3941  2020-01-01 03:00:00+01:00      1       1             0   \n",
       "3          86.6259  2020-01-01 03:15:00+01:00      1       1             0   \n",
       "4          86.3420  2020-01-01 03:30:00+01:00      1       1             0   \n",
       "\n",
       "   temperature_lag1  ...  wind_prediction_mw_lag3  wind_prediction_mw_lag4  \\\n",
       "0          134.6573  ...                  64.3057                  66.9774   \n",
       "1          134.6351  ...                  61.1283                  64.3057   \n",
       "2          134.6129  ...                  57.2304                  61.1283   \n",
       "3          134.5925  ...                  53.9495                  57.2304   \n",
       "4          134.5740  ...                  50.5166                  53.9495   \n",
       "\n",
       "   wind_prediction_mw_lag5  wind_prediction_mw_lag6  solar_prediction_mw_lag1  \\\n",
       "0                  69.2968                  70.8654                       0.0   \n",
       "1                  66.9774                  69.2968                       0.0   \n",
       "2                  64.3057                  66.9774                       0.0   \n",
       "3                  61.1283                  64.3057                       0.0   \n",
       "4                  57.2304                  61.1283                       0.0   \n",
       "\n",
       "   solar_prediction_mw_lag2  solar_prediction_mw_lag3  \\\n",
       "0                       0.0                       0.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       0.0                       0.0   \n",
       "3                       0.0                       0.0   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   solar_prediction_mw_lag4  solar_prediction_mw_lag5  \\\n",
       "0                       0.0                       0.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       0.0                       0.0   \n",
       "3                       0.0                       0.0   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   solar_prediction_mw_lag6  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign all the train data into DFs\n",
    "for train_data in os.listdir(TRAIN_DIR):\n",
    "    locals()['df_' + train_data[5:-4]] = pd.read_csv(TRAIN_DIR + '/' + train_data)\n",
    "    print(f'The local variable of type DataFrame, df_{train_data[5:-4]} is created')\n",
    "\n",
    "df_train_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The local variable of type DataFrame, df_test_4 is created\n",
      "The local variable of type DataFrame, df_test_1 is created\n",
      "The local variable of type DataFrame, df_test_2 is created\n",
      "The local variable of type DataFrame, df_test_3 is created\n",
      "The local variable of type DataFrame, df_outlier_test_4 is created\n",
      "The local variable of type DataFrame, df_outlier_test_1 is created\n",
      "The local variable of type DataFrame, df_outlier_test_3 is created\n",
      "The local variable of type DataFrame, df_outlier_test_2 is created\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>solar_ghi</th>\n",
       "      <th>solar_prediction_mw</th>\n",
       "      <th>wind_prediction_mw</th>\n",
       "      <th>load_actuals_mw</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>month</th>\n",
       "      <th>season</th>\n",
       "      <th>workdayornot</th>\n",
       "      <th>temperature_lag1</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_prediction_mw_lag3</th>\n",
       "      <th>wind_prediction_mw_lag4</th>\n",
       "      <th>wind_prediction_mw_lag5</th>\n",
       "      <th>wind_prediction_mw_lag6</th>\n",
       "      <th>solar_prediction_mw_lag1</th>\n",
       "      <th>solar_prediction_mw_lag2</th>\n",
       "      <th>solar_prediction_mw_lag3</th>\n",
       "      <th>solar_prediction_mw_lag4</th>\n",
       "      <th>solar_prediction_mw_lag5</th>\n",
       "      <th>solar_prediction_mw_lag6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142.5783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.4705</td>\n",
       "      <td>79.7650</td>\n",
       "      <td>2020-06-01 00:00:00+02:00</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>142.6783</td>\n",
       "      <td>...</td>\n",
       "      <td>113.2723</td>\n",
       "      <td>116.0008</td>\n",
       "      <td>119.1572</td>\n",
       "      <td>122.0776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142.4826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.4799</td>\n",
       "      <td>78.5278</td>\n",
       "      <td>2020-06-01 00:15:00+02:00</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>142.5783</td>\n",
       "      <td>...</td>\n",
       "      <td>112.6894</td>\n",
       "      <td>113.2723</td>\n",
       "      <td>116.0008</td>\n",
       "      <td>119.1572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>142.3870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.2095</td>\n",
       "      <td>77.1661</td>\n",
       "      <td>2020-06-01 00:30:00+02:00</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>142.4826</td>\n",
       "      <td>...</td>\n",
       "      <td>110.7785</td>\n",
       "      <td>112.6894</td>\n",
       "      <td>113.2723</td>\n",
       "      <td>116.0008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142.2914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.4468</td>\n",
       "      <td>77.1635</td>\n",
       "      <td>2020-06-01 00:45:00+02:00</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>142.3870</td>\n",
       "      <td>...</td>\n",
       "      <td>87.4705</td>\n",
       "      <td>110.7785</td>\n",
       "      <td>112.6894</td>\n",
       "      <td>113.2723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142.1993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.9961</td>\n",
       "      <td>77.1047</td>\n",
       "      <td>2020-06-01 01:00:00+02:00</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>142.2914</td>\n",
       "      <td>...</td>\n",
       "      <td>85.4799</td>\n",
       "      <td>87.4705</td>\n",
       "      <td>110.7785</td>\n",
       "      <td>112.6894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   temperature  solar_ghi  solar_prediction_mw  wind_prediction_mw  \\\n",
       "0     142.5783        0.0                  0.0             87.4705   \n",
       "1     142.4826        0.0                  0.0             85.4799   \n",
       "2     142.3870        0.0                  0.0             85.2095   \n",
       "3     142.2914        0.0                  0.0             86.4468   \n",
       "4     142.1993        0.0                  0.0             89.9961   \n",
       "\n",
       "   load_actuals_mw                  timestamp  month  season  workdayornot  \\\n",
       "0          79.7650  2020-06-01 00:00:00+02:00      6       3             0   \n",
       "1          78.5278  2020-06-01 00:15:00+02:00      6       3             0   \n",
       "2          77.1661  2020-06-01 00:30:00+02:00      6       3             0   \n",
       "3          77.1635  2020-06-01 00:45:00+02:00      6       3             0   \n",
       "4          77.1047  2020-06-01 01:00:00+02:00      6       3             0   \n",
       "\n",
       "   temperature_lag1  ...  wind_prediction_mw_lag3  wind_prediction_mw_lag4  \\\n",
       "0          142.6783  ...                 113.2723                 116.0008   \n",
       "1          142.5783  ...                 112.6894                 113.2723   \n",
       "2          142.4826  ...                 110.7785                 112.6894   \n",
       "3          142.3870  ...                  87.4705                 110.7785   \n",
       "4          142.2914  ...                  85.4799                  87.4705   \n",
       "\n",
       "   wind_prediction_mw_lag5  wind_prediction_mw_lag6  solar_prediction_mw_lag1  \\\n",
       "0                 119.1572                 122.0776                       0.0   \n",
       "1                 116.0008                 119.1572                       0.0   \n",
       "2                 113.2723                 116.0008                       0.0   \n",
       "3                 112.6894                 113.2723                       0.0   \n",
       "4                 110.7785                 112.6894                       0.0   \n",
       "\n",
       "   solar_prediction_mw_lag2  solar_prediction_mw_lag3  \\\n",
       "0                       0.0                       0.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       0.0                       0.0   \n",
       "3                       0.0                       0.0   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   solar_prediction_mw_lag4  solar_prediction_mw_lag5  \\\n",
       "0                       0.0                       0.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       0.0                       0.0   \n",
       "3                       0.0                       0.0   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   solar_prediction_mw_lag6  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign all the test data into DFs\n",
    "for test_data in os.listdir(TEST_DIR):\n",
    "    locals()['df_' + test_data[5:-4]] = pd.read_csv(TEST_DIR + '/' + test_data)\n",
    "    print(f'The local variable of type DataFrame, df_{test_data[5:-4]} is created')\n",
    "df_test_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create design matrix - each column in this matrix represents a model feature and each row is a training example. We remove the *demand* and *timeStamp* variables as they are not model features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that can retutn all the DataFrames of the training & testing variables\n",
    "# making it easier to modify all the variables at once. This\n",
    "\n",
    "# def modify_all_df(function: Callable) -> None:\n",
    "#     for df_key in locals().keys():\n",
    "#         if 'data_' in df_key:\n",
    "#             # locals[df_key].apply(lambda x: function)\n",
    "#             function(locals()[df_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['df_train_4',\n",
       " 'df_train_3',\n",
       " 'df_train_2',\n",
       " 'df_train_1',\n",
       " 'df_outlier_train_4',\n",
       " 'df_outlier_train_3',\n",
       " 'df_outlier_train_2',\n",
       " 'df_outlier_train_1']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "train_regex = re.compile(r'df_(\\w+_)?train_\\d')\n",
    "train_variable_list = list(filter(train_regex.match, locals().keys()))\n",
    "train_variable_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The varaible, X_train_4 is created.\n",
      "The varaible, Y_train_4 is created.\n",
      "The varaible, X_train_3 is created.\n",
      "The varaible, Y_train_3 is created.\n",
      "The varaible, X_train_2 is created.\n",
      "The varaible, Y_train_2 is created.\n",
      "The varaible, X_train_1 is created.\n",
      "The varaible, Y_train_1 is created.\n",
      "The varaible, X_outlier_train_4 is created.\n",
      "The varaible, Y_outlier_train_4 is created.\n",
      "The varaible, X_outlier_train_3 is created.\n",
      "The varaible, Y_outlier_train_3 is created.\n",
      "The varaible, X_outlier_train_2 is created.\n",
      "The varaible, Y_outlier_train_2 is created.\n",
      "The varaible, X_outlier_train_1 is created.\n",
      "The varaible, Y_outlier_train_1 is created.\n"
     ]
    }
   ],
   "source": [
    "# set the X for every training data, by dropping the 'timestamp' & 'local_actual_mv' columns\n",
    "for train_var in train_variable_list:\n",
    "        locals()[f'X_{train_var[3:]}'] = locals()[train_var].drop(['timestamp', 'load_actuals_mw'], axis = 1)\n",
    "        print(f'The varaible, X_{train_var[3:]} is created.')\n",
    "\n",
    "        locals()[f'Y_{train_var[3:]}'] = locals()[train_var]['load_actuals_mw']\n",
    "        print(f'The varaible, Y_{train_var[3:]} is created.')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_regex = re.compile(r'(\\w+_)?test_\\d')\n",
    "# test_variable_list = list(filter(test_regex.match, locals().keys()))\n",
    "# test_variable_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set the Y for every training data, by selecting only the 'load_actuals_mw' columns\n",
    "# for test_var in test_variable_list:\n",
    "#         locals()[f'Y_{train_var}'] = locals()[train_var]['load_actuals_mw']\n",
    "#         print(f'The varaible, Y_{train_var} is created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create predictive model pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use sklearn's Pipeline functionality to create a predictive model pipeline. For this model, the pipeline implements the following steps:\n",
    "- **one-hot encode categorical variables** - this creates a feature for each unique value of a categorical feature. For example, the feature *dayofweek* has 7 unique values. This feature is split into 7 individual features dayofweek0, dayofweek1, ... , dayofweek6. The value of these features is 1 if the timeStamp corresponds to that day of the week, otherwise it is 0.\n",
    "- **recursive feature elimination with cross validation (RFECV)** - it is often the case that some features add little predictive power to a model and may even make the model accuracy worse. Recursive feature elimination tests the model accuracy on increasingly smaller subsets of the features to identify the subset which produces the most accurate model. Cross validation is used to test each subset on multiple folds of the input data. The best model is that which achieves the lowest mean squared error averaged across the cross validation folds.\n",
    "- **train final model** - the best model found in after the feature elimination process is used to train the final estimator on the whole dataset.\n",
    "\n",
    "Identify indices for categorical columns for one hot encoding and create the OneHotEncoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 7, 8]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_cols = ['month', 'season', 'workdayornot']\n",
    "sample_df = locals()[\"df_train_1\"] # Cuz all the DFs' structure are the same, so we'll only need one sample for the col index\n",
    "dummy_cols_index = [sample_df.columns.get_loc(col) for col in sample_df.columns if col in dummy_cols]\n",
    "dummy_cols_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(remainder='passthrough',\n",
       "                  transformers=[('encoder', OneHotEncoder(sparse=False),\n",
       "                                 [6, 7, 8])])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = ColumnTransformer([('encoder', OneHotEncoder(sparse=False), dummy_cols_index)], remainder='passthrough')\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the linear regression model object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression(fit_intercept=True)\n",
    "lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For hyperparameter tuning and feature selection, cross validation will be performed using the training set. With time series forecasting, it is important that test data comes from a later time period than the training data. This also applies to each fold in cross validation. Therefore a time series split is used to create three folds for cross validation as illustrated below. Each time series plot represents a separate training/test split, with the training set coloured in blue and the test set coloured in red. Note that, even in the first split, the training data covers at least a full year so that the model can learn the annual seasonality of the demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demand_ts = df_train_1[['timestamp', 'load_actuals_mw']].copy()\n",
    "# demand_ts.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# for split_num, split_idx  in enumerate(tscv.split(demand_ts)):\n",
    "#     split_num = str(split_num)\n",
    "#     train_idx = split_idx[0]\n",
    "#     test_idx = split_idx[1]\n",
    "#     demand_ts['fold' + split_num] = \"not used\"\n",
    "#     demand_ts.loc[train_idx, 'fold' + split_num] = \"train\"\n",
    "#     demand_ts.loc[test_idx, 'fold' + split_num] = \"test\"\n",
    "\n",
    "# gs = gridspec.GridSpec(3,1)\n",
    "# fig = plt.figure(figsize=(15, 10), tight_layout=True)\n",
    "\n",
    "# ax = fig.add_subplot(gs[0])\n",
    "# ax.plot(demand_ts.loc[demand_ts['fold0']==\"train\", \"timestamp\"], demand_ts.loc[demand_ts['fold0']==\"train\", \"load_actuals_mw\"], color='b')\n",
    "# ax.plot(demand_ts.loc[demand_ts['fold0']==\"test\", \"timestamp\"], demand_ts.loc[demand_ts['fold0']==\"test\", \"load_actuals_mw\"], 'r')\n",
    "# ax.plot(demand_ts.loc[demand_ts['fold0']==\"not used\", \"timestamp\"], demand_ts.loc[demand_ts['fold0']==\"not used\", \"timestamp\"], demand_ts.loc[demand_ts['fold0']==\"not used\", \"load_actuals_mw\"], 'w')\n",
    "\n",
    "# ax = fig.add_subplot(gs[1], sharex=ax)\n",
    "# plt.plot(demand_ts.loc[demand_ts['fold1']==\"train\", \"timestamp\"], demand_ts.loc[demand_ts['fold1']==\"train\", \"load_actuals_mw\"], 'b')\n",
    "# plt.plot(demand_ts.loc[demand_ts['fold1']==\"test\", \"timestamp\"], demand_ts.loc[demand_ts['fold1']==\"test\", \"load_actuals_mw\"], 'r')\n",
    "# plt.plot(demand_ts.loc[demand_ts['fold1']==\"not used\", \"timestamp\"], demand_ts.loc[demand_ts['fold1']==\"not used\", \"load_actuals_mw\"], 'w')\n",
    "\n",
    "# ax = fig.add_subplot(gs[2], sharex=ax)\n",
    "# plt.plot(demand_ts.loc[demand_ts['fold2']==\"train\", \"timestamp\"], demand_ts.loc[demand_ts['fold2']==\"train\", \"load_actuals_mw\"], 'b')\n",
    "# plt.plot(demand_ts.loc[demand_ts['fold2']==\"test\", \"timestamp\"], demand_ts.loc[demand_ts['fold2']==\"test\", \"load_actuals_mw\"], 'r')\n",
    "# plt.plot(demand_ts.loc[demand_ts['fold2']==\"not used\", \"timestamp\"], demand_ts.loc[demand_ts['fold2']==\"not used\", \"load_actuals_mw\"], 'w')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the RFECV object. Note the metric for evaluating the model on each fold is the negative mean squared error. The best model is that which maximises this metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_cv = RFECV(estimator=lr,\n",
    "             cv=tscv,\n",
    "             scoring='neg_mean_squared_error',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model pipeline object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipeline = Pipeline([('preprocessor', preprocessor), ('rfecv', regr_cv)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model pipeline. This should only take a few seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipeline.fit(X_train_1, Y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run.log(\"pipeline steps\", regr_pipe.named_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trained model pipeline object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(WORKDIR, MODEL_NAME + '.pkl'), 'wb') as f:\n",
    "    pickle.dump(lr_pipeline, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore cross validation results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best CV negative mean squared error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run.log(\"best CV negMSE\", max(regr_pipe.named_steps['rfecv'].grid_scores_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Plot the cross validation errors with each subset of features. The chart shows that most features are useful to the model. However, the error gets significantly worse when there are 44 features or less in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame.from_dict({'cv_score': lr_pipeline.named_steps['rfecv'].grid_scores_})\n",
    "cv_results['mean_squared_error'] = cv_results['cv_score']\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(cv_results.index, cv_results['mean_squared_error'])\n",
    "plt.xlabel('number of features')\n",
    "plt.title('CV negative mean squared error')\n",
    "# run.log_image(\"CV errors plot\", plot=plt)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of features selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipeline.named_steps['rfecv'].n_features_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify supported features after selection process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onehot_cols(X):\n",
    "    X_dummy_cols = list(pd.get_dummies(X.copy()[dummy_cols], columns=dummy_cols).columns)\n",
    "    other_cols = list(X.columns.drop(dummy_cols))\n",
    "    return X_dummy_cols + other_cols\n",
    "\n",
    "supported_features = pd.DataFrame.from_dict(\n",
    "    {'feature':get_onehot_cols(X), \n",
    "     'supported':lr_pipeline.named_steps['rfecv'].support_}\n",
    ")\n",
    "supported_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect model coefficients for each included feature. The magnitude and direction of the coefficients indicates the effect the features has on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coefs = supported_features.loc[supported_features['supported'], ].copy()\n",
    "coefs['coefficients'] = lr_pipeline.named_steps['rfecv'].estimator_.coef_\n",
    "coefs.plot.bar('feature', 'coefficients', figsize=(15, 3), legend=False)\n",
    "# run.log_image(\"LR coefs per feature\", plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run.complete()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "15eb2d70be7d7d9baddaf6c9c4fecdefddeb65a737952d883f3b0e583de09784"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('mlops_train': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
